{
  "policyUpi": "PC-GCP-GKE-364",
  "policyId": "f5db1fcd-aa46-490e-9068-dd499ddb364b",
  "policyType": "config",
  "cloudType": "gcp",
  "severity": "low",
  "name": "GCP Kubernetes Engine Clusters not configured with private nodes feature",
  "description": "This policy identifies Google Kubernetes Engine (GKE) Clusters which are not configured with the private nodes feature. Private nodes feature makes your master inaccessible from the public internet and nodes do not have public IP addresses, so your workloads run in an environment that is isolated from the internet.",
  "rule.criteria": "5e4752d9-554b-4a6b-bad3-b41ba62fa6f7",
  "searchModel.query": "config from cloud.resource where cloud.type = 'gcp' AND api.name = 'gcloud-container-describe-clusters' AND json.rule = 'privateClusterConfig.enablePrivateNodes does not exist or privateClusterConfig.enablePrivateNodes is false'",
  "recommendation": "GCP Kubernetes private node feature can be enabled at the time of cluster creation. So to fix this alert, Create a new cluster with a private node feature enabled on it and migrate all required data from reported cluster to the newly created cluster and delete reported Kubernetes engine cluster.\n\nTo create new Kubernetes engine cluster with private node feature enabled, perform the following: \n1. Login to GCP Portal\n2. Go to Kubernetes Engine (Left Panel)\n3. Select Kubernetes clusters\n4. Click on CREATE CLUSTER button\n5. Click on 'Advanced options'\n6. Under the Networking section, Check the 'Enable VPC-native (using alias IP)' option\n7. Choose the required Network, Node subnet parameters\n8. From Network security, select the Private cluster check box.\n9. To create a master that is accessible from authorized external IP ranges, keep the 'Access master using its external IP address' checkbox selected.\n9. Set 'Master IP range' to as per your required IP range\n10. Click on 'Create'\nNOTE: When you create a private cluster, you must specify a /28 CIDR range for the VMs that run the Kubernetes master components.\n\nTo delete reported Kubernetes engine cluster, perform the following:\n1. Login to GCP Portal\n2. Go to Kubernetes Engine (Left Panel)\n3. Select Kubernetes clusters \n4. Click on reported Kubernetes cluster\n5. Click on the DELETE button\n6. On 'Delete a cluster' popup dialog, Click on DELETE to confirm the deletion of the cluster.",
  "remediable": false,
  "remediation.cliScriptTemplate": "",
  "remediation.description": "",
  "remediation.impact": "",
  "compliance.standard": [
    "ACSC Information Security Manual (ISM)",
    "APRA (CPS 234) Information Security",
    "Brazilian Data Protection Law (LGPD)",
    "CCPA 2018",
    "CIS Controls v7.1",
    "CIS Controls v8",
    "CIS Controls v8.1",
    "CIS v1.1.0 (GKE)",
    "CIS v1.2.0 (GKE)",
    "CIS v1.3.0 (GKE) - Level 1",
    "CIS v1.4.0 (GKE) - Level 1",
    "CIS v1.5.0 (GKE) - Level 1",
    "CRI Profile v1.2.1",
    "CSA CCM v.4.0.1",
    "Cybersecurity Maturity Model Certification (CMMC) v.1.02",
    "HITRUST v.9.4.2 [Deprecated]",
    "ISO 27002:2022",
    "ISO/IEC 27001:2022",
    "ISO/IEC 27002:2013",
    "ISO/IEC 27017:2015",
    "ISO/IEC 27018:2019",
    "NIST CSF",
    "NIST SP 800-171 Revision 2",
    "NIST SP 800-172",
    "PCI DSS v3.2.1",
    "PCI DSS v4.0",
    "PIPEDA",
    "RBI Baseline Cyber Security and Resilience Requirements",
    "Sarbanes Oxley Act (SOX)",
    "Secure Controls Framework (SCF) - 2022.2.1"
  ]
}